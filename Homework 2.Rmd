---
title: "Homework 2"
author: "Mari Sanders"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ResourceSelection)
library(MASS)
```

# Problem 1 

*Linear Regression*

- Uses continuous outcome variables.

- Assumes a linear relationship between the outcome and predictors.

- Coefficients represent the change in the dependent variable for a one-unit change in an independent variable.

- Errors are assumed to be normally distributed.

- Output is continuous and can take any real number.

- Uses RMSE or MSE to evaluate model fit

*Logistic Regression*

- Uses binary or categorical outcome variables.

- Models non-linear relationships using the logit function and probabilities.

- Coefficients are expressed as log odds, meaning a unit change in an independent variable affects the log odds of the outcome.

- Errors follow a binomial distribution.

- Output is a probability between 0 and 1.

- Uses deviance and score to evaluate model fit

# Problem 2 
$Odds = \frac{pi}{1-pi}$, which is the probability of an event occurring over the probability of the event not occurring. If you do $e^{\beta}$ to the coefficients in logistic regression, you will get the odds ratio. This is interpretable because it is in terms of the original equation and also easy to understand. 

$log(odds) = log(pi/1-pi)$, which is the probability of odds ratio given that the values are in terms of log, which is less interpretable. The coefficients $\beta$ in logistic regression are in terms of log odds, such that a change in log-odds for a one-unit increase in the outcome. 
f
# Problem 3 


L1 Regularization: Adds the absolute value of the sum of coefficients as a penalty term to the RSS. Lasso makes some of the coefficients go to zero. 

L2 Regularization: Adds the squared sum  of coefficients as the penalty term to the RSS.  Ridge/L2 regularization shrinks coefficients toward each other so that they can borrow strength from each other, but does not shrink any coefficients to zero. 


# Problem 4 



# Problem 5

## Logit

```{r}
dose <- c(0,1,2,3,4)
dying <- c(2, 8, 15, 23, 27)
tested <- rep(30,5)
data <- data.frame(dose, tested, dying)

resp <- cbind(died = data$dying, alive = tested - data$dying) 
pred <- data$dose

fitlogit <- glm(resp~pred,family=binomial(link='logit'),data= data)
summary(fitlogit)
beta_1 <- exp(fitlogit$coefficient[2])
confint(fitlogit) 
confint_logit <- exp(confint(fitlogit))
devfitlogit <- sum(residuals(fitlogit,type='deviance')^2)
predictionlogit <- predict(fitlogit, data.frame(pred = 0.01), se.fit=TRUE,type='response')

cat("Estimate:", exp(fitlogit$coefficients[2]), "\n",
    "CI:", c(confint_logit[2,1], confint_logit[2,2]), "\n",
    "Deviance:", devfitlogit, "\n",
    "P(dying|x=0.01):", predictionlogit$fit, "\n")
```



## Probit

```{r}
fitprobit <- glm(resp~pred,family=binomial(link='probit'),data= data)
summary(fitprobit)
confint(fitprobit) 
confint_probit <- exp(confint(fitprobit))
devprobit <- sum(residuals(fitprobit,type='deviance')^2)

predictionprobit <- predict(fitprobit, data.frame(pred = 0.01), se.fit = TRUE,type = 'response')
cat("Estimate:", exp(fitprobit$coefficients[2]), "\n",
    "CI:", c(confint_probit[2,1], confint_probit[2,2]), "\n",
    "Deviance:", devprobit, "\n",
    "P(dying|x=0.01):", predictionprobit$fit, "\n")
```


## Cloglog

```{r}
fitcloglog <- glm(resp~pred, family = binomial(link = "cloglog"), data = data)
summary(fitcloglog)
confint(fitcloglog) 
confint_cloglog <- exp(confint(fitcloglog))
devcloglog <- sum(residuals(fitcloglog,type = 'deviance')^2)

predictcloglog <- predict(fitcloglog, data.frame(pred =0.01), se.fit=TRUE,type='response')

cat("Estimate:", exp(fitcloglog$coefficients[2]), "\n",
    "CI:", c(confint_cloglog[2,1], confint_cloglog[2,2]), "\n",
    "Deviance:", devcloglog, "\n",
    "P(dying|x=0.01):", predictcloglog$fit, "\n")
```


### b) 

```{r}
beta0 <-  fitlogit$coefficients[1]
beta1 <- fitlogit$coefficients[2]
betacov <- vcov(fitlogit) 
x0fit <- -beta0/beta1
exp(x0fit)
varx0=betacov[1,1]/(beta1^2)+betacov[2,2]*(beta0^2)/(beta1^4)-2*betacov[1,2]*beta0/(beta1^3)
c(x0fit,sqrt(varx0)) # point est and se
exp((x0fit+c(qnorm(0.05),-qnorm(0.05))*sqrt(varx0))) # 90% CI for LD50
```

We are 90% confident that the LD50 for this bioassay study is between 5.509631 and 9.9095. 

# Problem 6 

```{r}
amount <- seq(from = 10, to = 90, by = 5)
offers <- c(4, 6, 10, 12, 39, 36, 22, 14, 10, 12, 8, 9, 3, 1, 5, 2, 1)
enrolls <- c(0, 2, 4, 2, 12, 14, 10, 7, 5, 5, 3, 5, 2, 0, 4, 2, 1)
declined <- offers - enrolls 
data <- data.frame(amount, offers, enrolls, declined)

mphfit <- glm(cbind(enrolls, declined) ~ amount,
              family=binomial(link='logit'),data= data)
summary(mphfit)
```

### a) 

```{r}
devmph <- sum(residuals(mphfit,type='deviance')^2)

sum(residuals(mphfit,type='pearson')^2) 

pval=1-pchisq(devmph,17-2)


hl <- hoslem.test(mphfit$y, fitted(mphfit), g=10) 
hl
```

The p value is `r pval`, which means that we fail to reject the null hypothesis that there is no relationship between the predictors and the response. This means that the model fits the data ok. 
### b) 

```{r}
confint(mphfit)
exp(confint(mphfit))
```

For a  unit increase in amount, the odds of enrollment increases by 1.031434. 

We are 95% confident that the the odds ratio is between 1.01253611 and 1.0519063 meaning that a unit increase in the amount of money increases the odds of enrollment by 2%-5%. Since the confidence interval does not include 1, we can say that the effect is statistically significant. 

### c) 

```{r}
beta0 <- mphfit$coefficients[1]
beta1 <- mphfit$coefficients[2]
betacov <- vcov(mphfit)
log_odds <- log(0.4 / (1 - 0.4))
scholarship_needed <- (log_odds - beta0) / beta_1

var_x <- betacov[1,1] / (beta1^2) + 
        betacov[2,2] * (beta0 - log_odds)^2 / (beta1^4) - 
        2 * betacov[1,2] * (beta0 - log_odds) / (beta1^3)

se_x <- sqrt(var_x)

ci_lower <- scholarship_needed - 1.96 * se_x
ci_upper <- scholarship_needed + 1.96 * se_x

cat("Estimate:", scholarship_needed, "\n",
    "Standard Error:", se_x, "\n",
    "CI Lower:", ci_lower, "\n",
    "CI Upper:", ci_upper, "\n")
```


